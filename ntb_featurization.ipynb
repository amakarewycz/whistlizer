{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23531ac-f082-4e33-a1df-2bdab1225650",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Featurization Pipeline steps for Training and Inference\n",
    "\n",
    "### Important Instructions\n",
    "\n",
    "This notebook can be used in two ways.\n",
    "\n",
    "#### 1. generate a subset of a training set\n",
    "\n",
    "you'll need to provide 2 inputs: the video, and a whistle ground truth file.\n",
    "\n",
    "The ground truth file MUST be at the same folder as the video.  It also must have a similar basename as the video, but ending in *_0.groundtruth.whistle.txt*\n",
    "\n",
    "For example *5U5A9273.webm* and *5U5A9273_0.groundtruth.whistle.txt*\n",
    "\n",
    "The ground truth is a file listing seconds for each whistle where each line in in the following format \n",
    "*`[Minutes:]Seconds[.Milliseconds] [# Comment]`*\n",
    "\n",
    "> 2.9 <br>\n",
    "> 11.3 # plus cheers <br>\n",
    "> 30.38 <br>\n",
    "> 59.149 <br>\n",
    "> 1:06.49 <br>\n",
    "> 1:22.34 <br>\n",
    "\n",
    "running this notebook will create 2 files \n",
    " \n",
    "1. ending with *_swin_{low_1}_{high_1}.npy* where low_1 and high_1 are slice coordinates of the fft slice operation.\n",
    "\n",
    "2. ending in *_training_set_1.npy*\n",
    "\n",
    "\n",
    "#### 2. generate input features for inference\n",
    "\n",
    "you'll need to provide 1 input: the video\n",
    "\n",
    "running this notebook will create a file ending with _swin_{low_1}_{high_1}.npy where low_1 and high_1 are slice coordinates of the fft slice operation.\n",
    "\n",
    "Select the  [Stop](#Stop) Cell.  And **Run All Above Selected Cell**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "10c3bd5a-4e9b-48ac-a66f-2ff57adee697",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Given a video file extract the name, and create audio, the file name to store the extracted audio\n",
    "#\n",
    "video = \"5U5A9278.MOV\"\n",
    "video = \"IMG_2398.MOV\"\n",
    "video = \"IMG_2365.MOV\"\n",
    "\n",
    "# Input 1\n",
    "video = \"/Volumes/Stuff/youtube-dl-2/GH020192 [wj1Vc2QSdfI].webm\"\n",
    "\n",
    "name = video.split(\".\")\n",
    "audio = f\"{name[0]}.mp3\"\n",
    "\n",
    "# Input 2 (Optional)\n",
    "ground_truth_file = name[0]+\"_0.groundtruth.whistle.txt\"\n",
    "\n",
    "# Output 1\n",
    "inference_tensor_file=f\"{name[0]}_swin_{low_1}_{high_1}.npy\"\n",
    "\n",
    "# Output 2 (Optional)\n",
    "training_tensor_file=name[0]+\"_training_set_1.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3bc79-f4b5-4755-a7d7-ce39b9e0fc33",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a0993587-2dcb-4ff6-b6da-6704849363ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in /Volumes/Stuff/youtube-dl-2/GH020192 [wj1Vc2QSdfI].mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "\n",
    "b = mp.VideoFileClip(video)\n",
    "b.audio.write_audiofile(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f95b709-9fa5-4fb3-8b4b-c0f9e25ef0c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Filter the audio signal, bandpass between 2-7.9 K Hertz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d1ff0f49-10a6-44f6-b66e-281b34405023",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "y,sr = librosa.load(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d7113e-ac8b-4634-9d20-975c793aec8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transform\n",
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f08fca83-61e2-4f4c-85df-3b4b9f6d484c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "b, a = signal.iirfilter(17, [2000, 7900], rs=60,fs=sr,\n",
    "                         btype='band', analog=False, ftype='cheby2')\n",
    "y_f =signal.lfilter(b,a,y,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af17303-6b63-41ed-9b9a-bb71bff930b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179c1fa-0a94-4308-92b7-c87ef1e4b8a5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Specify frame size, frame_size_seconds\n",
    "\n",
    "Specify # sliding frames, hop_in_window_dimensions\n",
    "\n",
    "z - contains the sliding audio frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d1bc961-9ac5-4a2f-a15b-9681f6b6808f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hop_length=7717 frame_length=15435\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "frame_size_seconds=0.7\n",
    "frame_length=frame_size_seconds * sr\n",
    "hop_in_window_divisions = 2\n",
    "hop_length=frame_size_seconds / hop_in_window_divisions * sr\n",
    "frame_length_c=math.ceil(frame_length)\n",
    "frame_length= frame_length_c\n",
    "hop_length=math.floor(frame_length_c / hop_in_window_divisions)\n",
    "\n",
    "print(f\"hop_length={hop_length} frame_length={frame_length}\")\n",
    "\n",
    "#zz=librosa.util.frame(y_f,\n",
    "#                   frame_length=22050,\n",
    "#                   hop_length=7350,\n",
    "#                   axis=0,\n",
    "#                   writeable=False,\n",
    "#                   subok=False)\n",
    "\n",
    "z=librosa.util.frame(y_f,\n",
    "                   frame_length=frame_length_c,\n",
    "                   hop_length=math.floor(frame_length_c / hop_in_window_divisions),\n",
    "                   axis=0,\n",
    "                   writeable=False,\n",
    "                   subok=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b00868-15e5-49a4-9df2-c7b5ee2e3274",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87234440-4bea-4e56-a3c2-af477abdfdf9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Functions for taking the **fast fourier transform** of audio frames. \n",
    "\n",
    "And functions for finding the index range for slicing the fft frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ff297238-67d2-4d7d-a4b4-2a87645d5c94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def window_fft(y,n_fft=2048,hop_length=12000):\n",
    "    return librosa.stft(y,n_fft=n_fft,center=False,hop_length=hop_length)\n",
    "\n",
    "def find_bounds(n_fft=2048,sr=sr,low=2000,high=4000,ts=3):\n",
    "    freq=librosa.fft_frequencies(sr=sr,n_fft=n_fft)\n",
    "    low_= None\n",
    "    high_=None\n",
    "    j=0\n",
    "    for i in freq:\n",
    "\n",
    "        if low_ is None:\n",
    "            if i > low:\n",
    "                low_ = j\n",
    "        if low_ and high_ is None:\n",
    "            if i > high:\n",
    "                high_ = j-1\n",
    "        j=j+1\n",
    "\n",
    "    print(f\"low={low_} - hi={high_} x {ts} cross {(high_-low_)*ts} fft bins {len(freq)}\")\n",
    "    return (low_,high_)\n",
    "\n",
    "def find_bounds_bands(n_fft=nfft,ts=3):\n",
    "    return (find_bounds(n_fft, low=2000,high=4096,ts=ts),\n",
    "    find_bounds(n_fft, high=8000,low=6000,ts=ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c2eada10-f762-468f-ba05-0ab6ac926f1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import numpy as np\n",
    "\n",
    "nfft=512\n",
    "hop_length=math.ceil(frame_length_c)\n",
    "def sss(ar,index,n_fft,positive_example=True):\n",
    "    return window_fft(ar[index],n_fft=nfft,hop_length=hop_length)\n",
    "\n",
    "\n",
    "acc=None\n",
    "\n",
    "kk=sss(z,0,nfft,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3086ba95-9d76-4fd3-820d-c70eab2660b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Slice FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a63bee-ad34-4ea9-93b6-62382f89b9c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Logic for slicing the fft frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "489e25d7-ac05-4fde-b2a1-832d14b8591b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low=47 - hi=95 x 1 cross 48 fft bins 257\n",
      "low=140 - hi=185 x 1 cross 45 fft bins 257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2021, 48)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((low_1,high_1),(low_2,high_2))=find_bounds_bands(n_fft=nfft,ts=np.shape(kk)[1])\n",
    "\n",
    "for i in range(len(z)): # islice(indices,0,5,None):\n",
    "    kk=sss(z,i,nfft,True)\n",
    "    kk=np.concatenate(np.abs(np.array(kk)[np.s_[low_1:high_1]]))\n",
    "    if acc is not None:\n",
    "        acc=np.vstack((acc,kk)) #kk),axis=0)\n",
    "    else:\n",
    "        acc=kk\n",
    "        \n",
    "#kk=ss(z,1111,nfft,True)\n",
    "kk=acc\n",
    "#((low_1,high_1),(low_2,high_2))=find_bounds_bands(n_fft=nfft,ts=np.shape(kk)[1])\n",
    "\n",
    "np.shape(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b620fa0-213a-4876-86c5-6702339bc212",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Write Inference Feature Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe55364a-6d83-4644-a66a-c09ff63f1a44",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Save the features to a file that can be used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "709d97fc-57a8-4ea3-bcf8-a487e6a24de7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save(inference_tensor_file,kk,allow_pickle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60f153-0281-4f21-b4af-da7433a9ff75",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<a id=\"Stop\"></a>\n",
    "## Stop \n",
    "\n",
    "**ONLY PROCEED RUNNING THE NEXT CELLS IF YOU HAVE PROVIDED A GROUND TRUTH FILE WITH THIS VIDEO.**\n",
    "\n",
    "proceed to the next cells if this video will be used for training models\n",
    "\n",
    "The following logic will load the ground truth file, convert the times into positive judgements and marry them to the frames containing the input features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c559c4-0b65-44bf-8419-bb2aea0ce436",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load ground truth\n",
    "Logic for converting judgements in the whistle file format into frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1afae5e6-8f66-4fdf-bd56-e52af22f8f68",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def read(a_file):\n",
    "    with open(a_file,\"r\") as f:\n",
    "        lines = [parseMinSec(stripComments(\"#\")(line.rstrip())) for line in f ]\n",
    "        return lines\n",
    "\n",
    "def convert_judgement_in_seconds_to_frames(hop_length, judgements=[]): # frame_size,\n",
    "    for i in judgements:\n",
    "        a = i * sr / hop_length # sec * samples / sec / ( samples / frame ) = frame\n",
    "        a = math.floor(a)\n",
    "        yield iter(range(a,a+2))\n",
    "        \n",
    "def parseMinSec(cs):\n",
    "    minute = seconds = 0\n",
    "  \n",
    "    if ':' in cs:\n",
    "        left, right = cs.split(\":\")\n",
    "        minute = float(left) * 60\n",
    "        seconds = float(right)\n",
    "    else:\n",
    "        seconds = float(cs)\n",
    "    \n",
    "    return minute + seconds\n",
    "\n",
    "from itertools import takewhile\n",
    " \n",
    " \n",
    "# stripComments :: [Char] -> String -> String\n",
    "def stripComments(cs):\n",
    "    '''The lines of the input text, with any\n",
    "       comments (defined as starting with one\n",
    "       of the characters in cs) stripped out.\n",
    "    '''\n",
    "    def go(cs):\n",
    "        return lambda s: ''.join(\n",
    "            takewhile(lambda c: c not in cs, s)\n",
    "        ).strip()\n",
    "    return lambda txt: '\\n'.join(map(\n",
    "        go(cs),\n",
    "        txt.splitlines()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4330c-2470-4074-84d1-961362087a2b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Load the judgements into an array containing frame indices that should be positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f54f8671-1131-4782-b082-2e2c9d417f8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "indices=[item for i in convert_judgement_in_seconds_to_frames(\n",
    "    hop_length=hop_length,\n",
    "    judgements=read(ground_truth_file)) for item in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2810b0-b00f-47d5-a673-41afbd94880e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert the judgements into vector same length as number of frames.  \n",
    "Use np.put to set the indices of positive class from the previous step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adfef72-4434-4158-8457-2d1b47135dcf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create Judgement Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6dad0c60-fbf3-4d03-9f12-527d45ef0677",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gt = np.zeros(dtype=int,shape=(len(kk)))\n",
    "\n",
    "np.put(gt, indices, v=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8bdf01-1477-4f24-b715-b0c4683a3c80",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Marry the features matrix with judgments vector, resulting in a single matrix with the last column containing the judgments.  The model training logic will split the judgments back out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb0d7560-4e1c-4a8e-a257-164b82afeced",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kkk=np.column_stack((kk,gt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e861488-62af-4d62-8e0a-c39d7ea9fcde",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "verifying we have additional column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3aad3897-69ef-486f-a2ed-cdb6e879a3fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2021, 49)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(kkk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a8fd39-4567-4bc5-ac98-ab0d1bf0a384",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Write Training Tensor\n",
    "Save the married features+jugements to a file that can be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c5468d2-1eef-4101-b94a-4184f872ac99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.save(training_tensor_file,kkk,allow_pickle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}